{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Qd1egoJXHAG"
      },
      "outputs": [],
      "source": [
        "# check for the GPU provided in the runtime\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-28tCMuZIn0"
      },
      "outputs": [],
      "source": [
        "# using quiet method for controlling the log\n",
        "# for suppressing the colored errors and warning in the terminal\n",
        "!pip install --quiet transformers==4.1.1\n",
        "# pytorch lightning for smoother model training and data loading\n",
        "#!pip install --quiet https://github.com/PyTorchLightning/pytorch-lightning/releases/download/1.2.6/pytorch-lightning-1.2.6.tar.gz \n",
        "!pip install -q pytorch-lightning  \n",
        "# using HuggingFace tokenizers\n",
        "!pip install --quiet tokenizers==0.9.4\n",
        "# Google's sentencepiece\n",
        "!pip install --quiet sentencepiece==0.1.94"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HRG-0vqZkbx"
      },
      "outputs": [],
      "source": [
        "# argparse makes it easier to write user friendly command line interfaces\n",
        "import argparse\n",
        "# package for faster file name matching\n",
        "import glob\n",
        "# makiing directories for data \n",
        "import os\n",
        "# reading json files as the data is present in json files\n",
        "import json\n",
        "# time module for calculating the model runtime\n",
        "import time\n",
        "# Allows writing status messages to a file\n",
        "import logging\n",
        "# generate random float numbers uniformly\n",
        "import random\n",
        "# regex module for text \n",
        "import re\n",
        "# module provides various functions which work on \n",
        "# iterators too produce complex iterators\n",
        "from itertools import chain\n",
        "from string import punctuation\n",
        "\n",
        "# pandas for data manipulation\n",
        "import pandas as pd\n",
        "# numpy for array operations\n",
        "import numpy as np\n",
        "# PyTorch\n",
        "import torch\n",
        "# provides various classes representing file system paths\n",
        "# with appropriate semantics\n",
        "from pathlib import Path\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# splitting the data \n",
        "from sklearn.model_selection import train_test_split\n",
        "# ANSII color formatting for ouput in terminal\n",
        "from termcolor import colored\n",
        "# wrapping paragraphs into string\n",
        "import textwrap\n",
        "\n",
        "# model checkpoints in pretrained model\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "'''\n",
        "optimizer - AdamW\n",
        "T5 Conditional Generator in which we'll give conditions\n",
        "T5 tokenizer because it is fast\n",
        "training the model without a learning rate\n",
        "'''\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    T5ForConditionalGeneration,\n",
        "    T5Tokenizer,\n",
        "    get_linear_schedule_with_warmup\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3g9RyS26ao6N"
      },
      "outputs": [],
      "source": [
        "# Seeds all the processes including numpy torch and other imported modules.\n",
        "pl.seed_everything(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLwmdXZwYBBD"
      },
      "outputs": [],
      "source": [
        "# check the version provided by Lightning\n",
        "import pytorch_lightning as pl\n",
        "print(pl.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP_baOyrhIBi"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('/content/pqa_train.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WVRRw_I3s5xK"
      },
      "outputs": [],
      "source": [
        "data['data'][1].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTtqg76Fgbx9"
      },
      "outputs": [],
      "source": [
        "# len \n",
        "len(data['data'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcYfBhQErm0D"
      },
      "outputs": [],
      "source": [
        "# We have a list of dictionaries in the \"data\". We can explore the 0th element\n",
        "data['data'][0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8qQqmUvggNp"
      },
      "outputs": [],
      "source": [
        "data['data'][1]['title']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pwN0LzAr5WF"
      },
      "outputs": [],
      "source": [
        "len(data['data'][0]['paragraphs'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osJEpTsIgnjJ"
      },
      "outputs": [],
      "source": [
        "questions = data['data'][1]['paragraphs']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cd6Ps2tlgym-"
      },
      "outputs": [],
      "source": [
        "# datapoint sample\n",
        "questions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLafI4AstqzH"
      },
      "source": [
        "# Function to Create a pandas dataframes of questions and answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzddd0tug2wR"
      },
      "outputs": [],
      "source": [
        "def extract_questions_and_answers(factoid_path ):\n",
        "  with factoid_path.open() as json_file:\n",
        "    data = json.load(json_file)\n",
        "    data_rows = []\n",
        "\n",
        "    for i in range(len(data['data'])):\n",
        "      #print(data['data'][i]['title'])\n",
        "      questions = data['data'][i]['paragraphs']\n",
        "      \n",
        "      for question in questions:\n",
        "        context = question['context']\n",
        "        for question_and_answers in question['qas']:\n",
        "          question = question_and_answers['question']\n",
        "          #print(question)\n",
        "          answers = question_and_answers['answers']\n",
        "          for answer in answers:\n",
        "            answer_text = answer['text']\n",
        "            answer_start = answer['answer_start']\n",
        "            answer_end = answer['answer_start'] + len(answer_text)  #Gets the end index of each answer in the paragraph\n",
        "            \n",
        "            data_rows.append({\n",
        "                  \"question\" : question,\n",
        "                  \"context\"  : context,\n",
        "                  \"answer_text\" : answer_text,\n",
        "                  \"answer_start\" : answer_start,\n",
        "                  \"answer_end\" : answer_end\n",
        "              })\n",
        "            #print(len(data_rows))\n",
        "  \n",
        "  return pd.DataFrame(data_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3kZ3Tl6kX6G"
      },
      "outputs": [],
      "source": [
        "factoid_path = Path(\"/content/pqa_train.json\")\n",
        "df = extract_questions_and_answers(factoid_path)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t64yrzc28S3M"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HVNoMGrnBLs"
      },
      "outputs": [],
      "source": [
        "sample_question = df.iloc[243]\n",
        "sample_question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k2I78NRWnNN3"
      },
      "outputs": [],
      "source": [
        "# Using textcolor to visualize the answer within the context\n",
        "\n",
        "def color_answer(question):\n",
        "  answer_start, answer_end = question[\"answer_start\"],question[\"answer_end\"]\n",
        "  context = question['context']\n",
        "\n",
        "  return  colored(context[:answer_start], \"white\") + \\\n",
        "    colored(context[answer_start:answer_end + 1], \"green\") + \\\n",
        "    colored(context[answer_end+1:], \"white\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sDkGTTUoOa3"
      },
      "outputs": [],
      "source": [
        "print(sample_question['question'])\n",
        "print()\n",
        "print(\"Answer: \")\n",
        "for wrap in textwrap.wrap(color_answer(sample_question), width = 100):\n",
        "  print(wrap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-rvJMpNt5Zo"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2ozZ4ptoYAN"
      },
      "outputs": [],
      "source": [
        "# using the base T5 model having 222M params\n",
        "MODEL_NAME ='t5-base'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hG3HGKFIAahG"
      },
      "outputs": [],
      "source": [
        "sample_question['context']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrtKKzO8pHAL"
      },
      "outputs": [],
      "source": [
        "'''tokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\n",
        "tokenizer.add_tokens(['!',\n",
        " '-',\n",
        " ' ',\n",
        " '_',\n",
        " '؛',\n",
        " '؟',\n",
        " 'ء',\n",
        " 'آ',\n",
        " 'ئ',\n",
        " 'ا',\n",
        " 'ب',\n",
        " 'ت',\n",
        " 'ث',\n",
        " 'ج',\n",
        " 'ح',\n",
        " 'خ',\n",
        " 'د',\n",
        " 'ذ',\n",
        " 'ر',\n",
        " 'ز',\n",
        " 'س',\n",
        " 'ش',\n",
        " 'ص',\n",
        " 'ض',\n",
        " 'ط',\n",
        " 'ظ',\n",
        " 'ع',\n",
        " 'غ',\n",
        " 'ف',\n",
        " 'ق',\n",
        " 'ل',\n",
        " 'م',\n",
        " 'ن',\n",
        " 'ه',\n",
        " 'و',\n",
        " '٪',\n",
        " 'پ',\n",
        " 'چ',\n",
        " 'ژ',\n",
        " 'ک',\n",
        " 'گ',\n",
        " 'ی',\n",
        " '۰',\n",
        " '۱',\n",
        " '۲',\n",
        " '۳',\n",
        " '۴',\n",
        " '۵',\n",
        " '۶',\n",
        " '۷',\n",
        " '۸',\n",
        " '۹'])\n",
        "#model.resize_token_embeddings(len(tokenizer))'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6MMTuviH_ds"
      },
      "outputs": [],
      "source": [
        "from transformers import BertConfig, BertTokenizer\n",
        "\n",
        "MODEL_NAME_OR_PATH = 'HooshvareLab/bert-fa-base-uncased'\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME_OR_PATH)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPG3rWMXKSyi"
      },
      "outputs": [],
      "source": [
        "sample_comment = \"ما در هوش‌واره معتقدیم با انتقال صحیح دانش و آگاهی، همه افراد میتوانند از ابزارهای هوشمند استفاده کنند. شعار ما هوش مصنوعی برای همه است.\"\n",
        "#tokenizer.tokenize(text)\n",
        "tokens = tokenizer.tokenize(sample_comment)\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f'  Comment: {sample_comment}')\n",
        "print(f'   Tokens: {tokenizer.convert_tokens_to_string(tokens)}')\n",
        "print(f'Token IDs: {token_ids}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rzskFH8OO6bd"
      },
      "outputs": [],
      "source": [
        "pred_translated = [\n",
        "         tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "         for gen_id in token_ids\n",
        "]\n",
        "print(pred_translated)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKxWSsdupHC2"
      },
      "outputs": [],
      "source": [
        "sample_encoding = tokenizer(f\"{sample_question['context']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83i_WzPGpyJR"
      },
      "outputs": [],
      "source": [
        "sample_encoding.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DWJlEbtLp1ap"
      },
      "outputs": [],
      "source": [
        "print(sample_encoding[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVEOLW6CqCCD"
      },
      "outputs": [],
      "source": [
        "print(sample_encoding[\"attention_mask\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44fV5Mauvp-F"
      },
      "outputs": [],
      "source": [
        "print(len(sample_encoding['input_ids']), len(sample_encoding['attention_mask']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIy8dTAJqFW0"
      },
      "outputs": [],
      "source": [
        "# Checking the decoding of the input ids\n",
        "\n",
        "preds = [\n",
        "         tokenizer.decode(input_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "         for input_id in sample_encoding['input_ids']\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi1xjpSVqeYc"
      },
      "outputs": [],
      "source": [
        "preds= \" \".join(preds)\n",
        "for wrap in textwrap.wrap(preds, width = 80):\n",
        "  print(wrap)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHFoy6akwCAi"
      },
      "source": [
        "There exists a special seperator token in between the question and its answers.\n",
        "\n",
        "Checking the encoding on the sample question"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N2_zfw8xqgBf"
      },
      "outputs": [],
      "source": [
        "encoding = tokenizer(\n",
        "    sample_question['question'],\n",
        "    sample_question['context'],\n",
        "    max_length=396,\n",
        "    padding='max_length',\n",
        "    truncation=\"only_second\",\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNgUeiafsQPX"
      },
      "outputs": [],
      "source": [
        "encoding.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TCcHThUsXgt"
      },
      "outputs": [],
      "source": [
        "tokenizer.special_tokens_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myaSEq9vsd20"
      },
      "outputs": [],
      "source": [
        "tokenizer.eos_token, tokenizer.eos_token_id\n",
        "# Input id of 1 represents end of sequence token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ND-qMS3MsssL"
      },
      "outputs": [],
      "source": [
        "# Text representation pf the input ids\n",
        "\n",
        "tokenizer.decode(encoding['input_ids'].squeeze())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4O94b5A7wfMw"
      },
      "source": [
        "## Creating the labels for the answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TArh_28mtGRC"
      },
      "outputs": [],
      "source": [
        "answer_encoding = tokenizer(\n",
        "    sample_question['answer_text'],\n",
        "    max_length=32,\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    return_attention_mask=True,\n",
        "    add_special_tokens=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MhbXR76tZJK"
      },
      "outputs": [],
      "source": [
        "tokenizer.decode(answer_encoding['input_ids'].squeeze())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3q5mC44tfSx"
      },
      "outputs": [],
      "source": [
        "labels = answer_encoding[\"input_ids\"]\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PiJpR5cwuPI"
      },
      "source": [
        "Labels after the end of sequence in the answer encoding has to be converted to -100 from 0 for the model evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocbgT0JDueVZ"
      },
      "outputs": [],
      "source": [
        "labels[labels == 0] = -100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qIroGAVulLI"
      },
      "outputs": [],
      "source": [
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0OrBRcPuodP"
      },
      "source": [
        "## To create dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YC84KMKxuqFN"
      },
      "outputs": [],
      "source": [
        "class QADataset(Dataset):\n",
        "  def __init__(\n",
        "      self,\n",
        "      data:pd.DataFrame,\n",
        "      tokenizer:T5Tokenizer,\n",
        "      source_max_token_len: int = 396,\n",
        "      target_max_token_len: int = 32,\n",
        "\n",
        "      ):\n",
        "    \n",
        "    self.data =  data\n",
        "    self.tokenizer =  tokenizer\n",
        "    self.source_max_token_len =  source_max_token_len\n",
        "    self.target_max_token_len =  target_max_token_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "\n",
        "  def __getitem__(self, index: int):\n",
        "    data_row = self.data.iloc[index]\n",
        "\n",
        "    source_encoding = tokenizer(\n",
        "      data_row['question'],\n",
        "      data_row['context'],\n",
        "      max_length=self.source_max_token_len,\n",
        "      padding='max_length',\n",
        "      truncation=\"only_second\",\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "      )\n",
        "    \n",
        "    target_encoding = tokenizer(\n",
        "      data_row['answer_text'],\n",
        "      max_length=self.target_max_token_len,\n",
        "      padding='max_length',\n",
        "      truncation=True,\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=True,\n",
        "      return_tensors=\"pt\"\n",
        "      )\n",
        "    \n",
        "    labels = target_encoding['input_ids']\n",
        "    labels[labels==0] = -100\n",
        "\n",
        "    return dict(\n",
        "        question=data_row['question'],\n",
        "        context=data_row['context'],\n",
        "        answer_text=data_row['answer_text'],\n",
        "        input_ids=source_encoding[\"input_ids\"].flatten(),\n",
        "        attention_mask=source_encoding['attention_mask'].flatten(),\n",
        "        labels=labels.flatten()\n",
        "    )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hI-CMUtuxkZz"
      },
      "outputs": [],
      "source": [
        "sample_dataset = QADataset(df, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eIfXyyObx3Kq"
      },
      "outputs": [],
      "source": [
        "for data in sample_dataset:\n",
        "  print(\"Question: \", data['question'])\n",
        "  print(\"Answer text: \", data['answer_text'])\n",
        "  print(\"Input_ids: \", data['input_ids'][:10])\n",
        "  print(\"Labels: \", data['labels'][:10])\n",
        "  break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD8JFfYJxCcl"
      },
      "source": [
        "## Splitting into train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXOHeMUVyIYS"
      },
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(df, test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Wv5RMMlyyvs"
      },
      "outputs": [],
      "source": [
        "train_df.shape,  val_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2uyNj_lcy73E"
      },
      "source": [
        "# Create pytorch lightning datamodule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLGivrpDy9ph"
      },
      "outputs": [],
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "  def __init__(\n",
        "      self,\n",
        "      train_df: pd.DataFrame,\n",
        "      test_df: pd.DataFrame,\n",
        "      tokenizer:T5Tokenizer,\n",
        "      batch_size: int = 8,\n",
        "      source_max_token_len: int = 396,\n",
        "      target_max_token_len: int = 32,\n",
        "      ):\n",
        "    super().__init__()\n",
        "    self.train_df = train_df\n",
        "    self.test_df = test_df\n",
        "    self.tokenizer = tokenizer\n",
        "    self.batch_size = batch_size\n",
        "    self.source_max_token_len = source_max_token_len\n",
        "    self.target_max_token_len = target_max_token_len\n",
        "\n",
        "  def setup(self, stage = None):\n",
        "    self.train_dataset = QADataset(\n",
        "        self.train_df,\n",
        "        self.tokenizer,\n",
        "        self.source_max_token_len,\n",
        "        self.target_max_token_len\n",
        "        )\n",
        "\n",
        "    self.test_dataset = QADataset(\n",
        "    self.test_df,\n",
        "    self.tokenizer,\n",
        "    self.source_max_token_len,\n",
        "    self.target_max_token_len\n",
        "    )\n",
        " \n",
        "  def train_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=4\n",
        "        )\n",
        "  def val_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        batch_size=self.batch_size,\n",
        "        num_workers=4\n",
        "        )\n",
        "\n",
        "  def test_dataloader(self):\n",
        "    return DataLoader(\n",
        "        self.test_dataset,\n",
        "        batch_size=1,\n",
        "        num_workers=4\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RCgqZshX2CLy"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 4\n",
        "N_EPOCHS = 3\n",
        "\n",
        "data_module = DataModule(train_df, val_df, tokenizer, batch_size=BATCH_SIZE)\n",
        "data_module.setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQCsI_RSrsI"
      },
      "source": [
        "## Building the PyTorch lightning module using T5ForConditionalGeneration model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yu2hpq8SLOi"
      },
      "outputs": [],
      "source": [
        "class QAModel(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = T5ForConditionalGeneration.from_pretrained(MODEL_NAME, return_dict=True)\n",
        "    self.model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, labels=None):\n",
        "    output = self.model(\n",
        "        input_ids, \n",
        "        attention_mask=attention_mask,\n",
        "        labels=labels)\n",
        "\n",
        "    return output.loss, output.logits\n",
        "\n",
        "  def training_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n",
        "    return {\"loss\": loss, \"predictions\":outputs, \"labels\": labels}\n",
        "\n",
        "  def validation_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def test_step(self, batch, batch_idx):\n",
        "    input_ids = batch['input_ids']\n",
        "    attention_mask=batch['attention_mask']\n",
        "    labels = batch['labels']\n",
        "    loss, outputs = self(input_ids, attention_mask, labels)\n",
        "    self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n",
        "    return loss\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "\n",
        "    optimizer = AdamW(self.parameters(), lr=0.0001)\n",
        "    return optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uX2RY1vK1YVr"
      },
      "outputs": [],
      "source": [
        "model = QAModel() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG9H_2goykbu"
      },
      "source": [
        "## Using trainer from pytorch lightning to finetune model using our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2kzoAS_Vcsd"
      },
      "outputs": [],
      "source": [
        "# To record the best performing model using checkpoint\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"best-checkpoint\",\n",
        "    save_top_k=1,\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6QnnPRGUxpq"
      },
      "outputs": [],
      "source": [
        "#logger = TensorBoardLogger(\"training-logs\", name=\"qa\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghzCmhl5W2Vi"
      },
      "outputs": [],
      "source": [
        "#logger = TensorBoardLogger(\"training-logs\", name=\"qa\")\n",
        "trainer = pl.Trainer(\n",
        "    #logger = logger,\n",
        "    callbacks= checkpoint_callback,\n",
        "    max_epochs=5,\n",
        "    gpus=1,\n",
        "    #progress_bar_refresh_rate = 30\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTX6GRpMzFh0"
      },
      "source": [
        "## Loading Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0DbRcMQYBFA"
      },
      "outputs": [],
      "source": [
        "#%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co6GUVELYIwM"
      },
      "outputs": [],
      "source": [
        "#%tensorboard --logdir ./lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtmszuLGyFO4"
      },
      "outputs": [],
      "source": [
        "#!rm --rf lightning_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLVpNh9hYSIF"
      },
      "outputs": [],
      "source": [
        "trainer.fit(model, data_module)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDAbkxtQYxzb"
      },
      "outputs": [],
      "source": [
        "#trainer.test()  # evaluate the model according to the last checkpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Bot5Waz6F_"
      },
      "source": [
        "# Predictions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -sh /content/checkpoints/best-checkpoint.ckpt"
      ],
      "metadata": {
        "id": "VPBCzg0MTenq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPH2sKbIz7uc"
      },
      "outputs": [],
      "source": [
        "#trained_model = QAModel.load_from_checkpoint(\"checkpoints/best-checkpoint.ckpt\")\n",
        "#trained_model.freeze() # "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIOml8Oe9kPb"
      },
      "source": [
        "## Generate answers for the questions in the validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_WjeOLJfz0h5"
      },
      "outputs": [],
      "source": [
        "trained_model = model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2uEi6rv0Oan"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question):\n",
        "  source_encoding=tokenizer(\n",
        "      question[\"question\"],\n",
        "      question['context'],\n",
        "      max_length = 396,\n",
        "      padding=\"max_length\",\n",
        "      truncation=\"only_second\",\n",
        "      return_attention_mask=True,\n",
        "      add_special_tokens=False,\n",
        "      return_tensors=\"pt\"\n",
        "\n",
        "  )\n",
        "\n",
        "  generated_ids = trained_model.model.generate(\n",
        "      input_ids=source_encoding[\"input_ids\"],\n",
        "      attention_mask=source_encoding[\"attention_mask\"],\n",
        "      num_beams=1,  # greedy search\n",
        "      max_length=80,\n",
        "      repetition_penalty=2.5,\n",
        "      early_stopping=True,\n",
        "      use_cache=True)\n",
        "  \n",
        "  preds = [\n",
        "          tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "          for generated_id in generated_ids\n",
        "  ]\n",
        "\n",
        "  return \"\".join(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TViaCgYM5h44"
      },
      "outputs": [],
      "source": [
        "sample_question = val_df.iloc[20]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38zxGKgzJ5c3"
      },
      "outputs": [],
      "source": [
        "sample_question[\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvBwizLcJ9jm"
      },
      "outputs": [],
      "source": [
        "sample_question[\"answer_text\"]  # Label Answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igRYEwO_KCmG"
      },
      "outputs": [],
      "source": [
        "print(generate_answer(sample_question))  # Predicted answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REdkokA6KIBf"
      },
      "outputs": [],
      "source": [
        "sample_question = val_df.iloc[66]\n",
        "sample_question[\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EwHbMQ_3K4HI"
      },
      "outputs": [],
      "source": [
        "sample_question[\"answer_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVVCDmBBKxXC"
      },
      "outputs": [],
      "source": [
        "generate_answer(sample_question)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyWKE9z3K78z"
      },
      "outputs": [],
      "source": [
        "sample_question = val_df.iloc[114]\n",
        "sample_question[\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LbRqkQcdK0EA"
      },
      "outputs": [],
      "source": [
        "sample_question[\"answer_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4UlN6x6BK9DY"
      },
      "outputs": [],
      "source": [
        "generate_answer(sample_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mOn-SqOn0IOV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xBgkI3R1U5o"
      },
      "outputs": [],
      "source": [
        "sample_question = val_df.iloc[10]\n",
        "sample_question[\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nHk6mXx1U5q"
      },
      "outputs": [],
      "source": [
        "sample_question[\"answer_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Cn1xNCx1U5r"
      },
      "outputs": [],
      "source": [
        "generate_answer(sample_question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IRQc7Hr1bgb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eDLVN3HUqZm"
      },
      "outputs": [],
      "source": [
        "sample_question = val_df.iloc[77]\n",
        "sample_question[\"question\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxebqxqZUqZo"
      },
      "outputs": [],
      "source": [
        "sample_question[\"answer_text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAbZBbEuUqZp"
      },
      "outputs": [],
      "source": [
        "generate_answer(sample_question)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LKJrobb2UtwY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}